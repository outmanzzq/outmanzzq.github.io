---
layout: post
title: K8S(07)交付实战-架构说明并准备zk集群
categories: k8s,docker
description: ZooKeeper 主要服务于分布式系统，可以用 ZooKeeper 来做：统一配置管理、统一命名服务、分布式锁、集群管理。
keywords: k8s,docker,zookeeper
---

> ZooKeeper 主要服务于分布式系统，可以用 ZooKeeper 来做：统一配置管理、统一命名服务、分布式锁、集群管理。

- Zookeeper 官网：<https://zookeeper.apache.org/>

## 1 交付的服务架构图：

![img](/images/20220419-k8s07-zookeeper-01.png)

### 1.1 架构图解

1. 最上面一排为 K8S 集群外服务
   1.1 代码仓库使用基于 Git 的 Gitee
   1.2 注册中心使用 3 台 ZooKeeper（zk） 组成集群
   1.3 用户通过 Ingress 暴露出去的服务进行访问

2. 中间层是 K8S 集群内服务
   2.1 Jenkins 以容器方式运行,数据目录通过共享磁盘做持久化
   2.2 整套 Dubbo 微服务都以 Pod 方式交付,通过zk集群通信
   2.3 需要提供的外部访问的服务通过 Ingress 方式暴露

3. 最下层是运维主机层
   3.1 Harbor 是 Docker 私有仓库,存放 Docker 镜像
   3.2 Pod 相关 yaml 文件创建在运维主机特定目录
   3.3 在 K8S 集群内通过 Nginx 提供的下载连接应用 YAML 配置

### 1.2 交付说明:

Docker 虽然可以部署有状态服务,但如果不是有特别需要,还是建议不要部署有状态服务
K8S 同理,也不建议部署有状态服务，如 mysql，zk 等。
因此手动将 Zookeeper 创建集群提供给 Dubbo 使用

## 2 部署 ZK 集群

集群主机分布：
- 7-11
- 7-12
- 7-21

zk 是 Java 服务，需要依赖 JDK

### 2.1 二进制安装 JDK

JDK 请自行下载,只要是 1.8 版本的就可以,RPM 安装或二进制安装均可：

#### 2.1.1 解压 JDK

```bash
mkdir /opt/src
mkdir /usr/java
cd /opt/src
tar -xf jdk-8u221-linux-x64.tar.gz -C /usr/java/
ln -s /usr/java/jdk1.8.0_221/ /usr/java/jdk
```

#### 2.1.2 写入环境变量

```bash
cat >>/etc/profile <<'EOF'
#JAVA HOME
export JAVA_HOME=/usr/java/jdk
export PATH=$JAVA_HOME/bin:$JAVA_HOME/bin:$PATH
export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar
EOF

# 使环境变量生效
source /etc/profile
```

验证结果

```sh
[root@hdss7-11 ~]# java -version
java version "1.8.0_221"
Java(TM) SE Runtime Environment (build 1.8.0_221-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)
```

## 2.2 二进制安装 zk

#### 2.2.1 下载 Zookeeper

[下载地址](https://archive.apache.org/dist/zookeeper/)

```SH
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz
tar -zxf zookeeper-3.4.14.tar.gz -C /opt/
ln -s /opt/zookeeper-3.4.14/ /opt/zookeeper
```

#### 2.2.2 创建 zk 配置文件：

```sh
cat >/opt/zookeeper/conf/zoo.cfg <<'EOF'
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/data/zookeeper/data
dataLogDir=/data/zookeeper/logs
clientPort=2181
server.1=zk1.zq.com:2888:3888
server.2=zk2.zq.com:2888:3888
server.3=zk3.zq.com:2888:3888
EOF
```

创建相关目录

```sh
mkdir -p /data/zookeeper/data
mkdir -p /data/zookeeper/logs
```

#### 2.2.3 创建集群配置

给每个 zk 不同的 myid,以便区分主从

```sh
#7-11上
echo 1 > /data/zookeeper/data/myid
#7-12上
echo 2 > /data/zookeeper/data/myid
#7-21上
echo 3 > /data/zookeeper/data/myid
```

#### 2.2.4 修改 DNS 解析

到 `7.11` 上增加 DNS 解析记录

```sh
vi /var/named/zq.com.zone
...
zk1        A    10.4.7.11
zk2        A    10.4.7.12
zk3        A    10.4.7.21

#验证结果
~]# dig -t A zk1.zq.com  +short
10.4.7.11
```
> 注意滚动 serial 编号

### 2.3 启动 zk 集群

### 2.3.1 启动 Zookeeper

在每台zk机器上都执行此操作

```python
/opt/zookeeper/bin/zkServer.sh start
```

#### 2.3.2 检查 zk 启动情况

```sh
~]# ss -ln|grep 2181
tcp    LISTEN     0      50       :::2181                 :::* 
```

#### 2.3.3 检查 zk 集群情况

```sh
[root@hdss7-11 ~]# /opt/zookeeper/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: follower

[root@hdss7-12 ~]# /opt/zookeeper/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: leader

[root@hdss7-21 ~]# /opt/zookeeper/bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: follower
```

到此，Zookeeper 集群就搭建好了。

## 3 准备 Java 运行底包

运维主机上操作

### 3.1 拉取原始底包

```sh
docker pull stanleyws/jre8:8u112
docker tag fa3a085d6ef1 harbor.zq.com/public/jre:8u112
docker push harbor.zq.com/public/jre:8u112
```

### 3.2 制作新底包

```sh
mkdir -p /data/dockerfile/jre8/
cd /data/dockerfile/jre8/
```

#### 3.2.1 制作 Dockerfile

```sh
cat >Dockerfile <<'EOF'
FROM harbor.zq.com/public/jre:8u112
RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\
    echo 'Asia/Shanghai' >/etc/timezone
ADD config.yml /opt/prom/config.yml
ADD jmx_javaagent-0.3.1.jar /opt/prom/
WORKDIR /opt/project_dir
ADD entrypoint.sh /entrypoint.sh
CMD ["sh","/entrypoint.sh"]
EOF
```

#### 3.2.2准备 Dockerfile 需要的文件

**添加 config.yml**

此文件是为后面用 Prometheus 监控做准备的

```sh
cat >config.yml <<'EOF'
--- 
rules: 
 - pattern: '.*'
EOF
```

**下载 jmx_javaagent,监控 JVM 信息：**

```sh
wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.3.1/jmx_prometheus_javaagent-0.3.1.jar -O jmx_javaagent-0.3.1.jar
```

**创建 entrypoint.sh 启动脚本：**

使用 exec 来运行 Java 的 Jar 包，能够使脚本将自己的 pid 为 ‘1’ 传递给 Java 进程，避免 Docker 容器因没有前台进程而退出。并且不要加 & 符。

```sh
cat >entrypoint.sh <<'EOF'
#!/bin/sh
M_OPTS="-Duser.timezone=Asia/Shanghai -javaagent:/opt/prom/jmx_javaagent-0.3.1.jar=$(hostname -i):${M_PORT:-"12346"}:/opt/prom/config.yml"
C_OPTS=${C_OPTS}
JAR_BALL=${JAR_BALL}
exec java -jar ${M_OPTS} ${C_OPTS} ${JAR_BALL}
EOF
```

#### 3.2.3 构建底包并上传

在 Harbor 中创建名为 `base` 的公开仓库,用来存放自己自定义的底包

```sh
docker build . -t harbor.zq.com/base/jre8:8u112
docker push  harbor.zq.com/base/jre8:8u112
```

> 原文链接：<https://www.cnblogs.com/noah-luo/p/13345242.html>